---
layout: post
comments: false 
title: "Pytorch中回归指标的计算方法" 
date: 2022-3-22
tags: study-log
---

> 实现Pytorch环境下对Mean Absolute Error, Mean Relative Error和Pearson Correlation等评价指标的计算和验证。

<!--more-->

最近在做RouteNet模型从Tensorflow到Pytorch的复现工作，发现Tensorflow中定义的一些评价API在Pytorch中并没有，就通过自己写轮子的方法进行了实现。用pytorch写的好处在于，在验证过程中可以不用将数据再迁移到cpu上计算，节约时间并提高计算速度。

# Mean Absolute Error
MAE的计算在Pytorch中被定义为L1Loss，因此可以在模型的初始化中定义一个L1Loss()方法，并在val中调用即可。
pytorch-lightning module的写法为：
```python
import pytorch-lightning as pl
import torch
class MyModel(pl.LightningModule):
    def init(self, xxx):
        ...
        self.mae_calc = torch.nn.L1Loss()

    def validation_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        mae = self.mae_calc(y_hat, y)
        ...
```

# Pearson Correlation
Pearsom Correlation在tensorflow中的API为`tf.contrib.metrics.streaming_pearson_correlation(labels, predictions)`，目的是计算预测和标签矩阵的相关系数矩阵。Pytorch中没有给出对应的API，但scipy库中有personr的计算，只是这种方法无法同时计算一个batch中的所有samples，因此通过参考知乎上的问题：[pytorch怎么计算矩阵的相关系数矩阵？](https://www.zhihu.com/question/450669124) 构建了pearsonr的计算方法：
```python
def pearsonr(self, y_pred, y_true):
        # y_pred: [batch, seq]
        # y_true: [batch, seq]
        y_pred, y_true = y_pred.view(-1), y_true.view(-1)
        centered_pred = y_pred - torch.mean(y_pred)
        centered_true = y_true - torch.mean(y_true)
        covariance = torch.sum(centered_pred * centered_true)
        bessel_corrected_covariance = covariance / (y_pred.size(0) - 1)
        std_pred = torch.std(y_pred, dim=0)
        std_true = torch.std(y_true, dim=0)
        corr = bessel_corrected_covariance / (std_pred * std_true)
        return corr
```

# Mean Relative Error

在tensorflow的[官方API文档](https://tensorflow.google.cn/api_docs/python/tf/compat/v1/metrics/mean_relative_error)中对该指标的定义为：

> The mean_relative_error function creates two local variables, total and count that are used to compute the mean relative absolute error.

所以我们可以认为，tf中的mean relative error其实等效为mean relative absolute error。

在Google中搜索mean relative absolute error pytorch后第一个结果告诉我，Pytorch-ignite包中实现了这个评价的计算，并给出了[计算公式](https://pytorch.org/ignite/generated/ignite.contrib.metrics.regression.MeanAbsoluteRelativeError.html#ignite.contrib.metrics.regression.MeanAbsoluteRelativeError)。但这个包对于计算封装的过于繁琐，就算安装后也难以直接调用，且为了一个简单的计算专门安装一个包也太不优雅了，于是决定根据公式自己实现一下。

此外在stack overflow冲浪的时候还看到一个R语言实现的RAE计算公式，那再套一个mean不就也是MRAE了吗。一时竟不知道哪个才是对的，只好写一个测试样例，分别计算一下，并和tf的做对比。其中需要注意三者在计算的过程中都使用float32类型，float32与float64在最终结果上会有差异，但不能算作计算不正确。

```python
import numpy as np
import tensorflow as tf
import scipy.stats as measures

y_pred = np.array([2, 2, 3, 4, 5, 5, 4, 2], dtype=np.float32)
y_true = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)

## R
val1 = np.mean(abs(y_true - y_pred) / abs(y_true - np.mean(y_true)))
print("val1: \t{}".format(val1))

## ignite
val2 = np.mean(abs(y_true - y_pred) / abs(y_true))
print("val2: \t{}".format(val2))

## Tensorflow
logits = tf.placeholder(tf.float32, [8])
labels = tf.to_float(tf.Variable(y_true))

acc, acc_op = tf.metrics.mean_relative_error(labels, logits, labels)

sess = tf.Session()
sess.run(tf.local_variables_initializer())
sess.run(tf.global_variables_initializer())
sess.run(acc, {logits:y_pred})
sess.run(acc_op, {logits:y_pred})

print("val3: \t{}".format(sess.run(acc,{logits:y_pred})))
```

最终计算结果为
```shell
val1:   0.4833333492279053
val2:   0.293154776096344
val3:   0.293154776096344
```

结论，ignite的计算公式是对的，按照val2的计算过程来写就能实现`tf.metrics.mean_relative_error`

PS：这个测试代码也可以用来测试其他tensorflow的API，很实用。

# 测试
最终需要测试自己造的轮子是否与Tensorflow API的计算结果相同。
```python
import numpy as np
import tensorflow as tf
import torch

def pearsonr(y_pred, y_true):
    # y_pred: [batch, seq]
    # y_true: [batch, seq]
    y_pred, y_true = y_pred.view(-1), y_true.view(-1)
    centered_pred = y_pred - torch.mean(y_pred)
    centered_true = y_true - torch.mean(y_true)
    covariance = torch.sum(centered_pred * centered_true)
    bessel_corrected_covariance = covariance / (y_pred.size(0) - 1)
    std_pred = torch.std(y_pred, dim=0)
    std_true = torch.std(y_true, dim=0)
    corr = bessel_corrected_covariance / (std_pred * std_true)
    return corr

y_pred = np.array([[2, 2, 3, 4, 5, 5, 4, 2]], dtype=np.float32)
y_true = np.array([[1, 2, 3, 4, 5, 6, 7, 8]], dtype=np.float32)


## pytorch
mae_calc = torch.nn.L1Loss()
y_hat = torch.tensor(y_pred)
y = torch.tensor(y_true)
mae = mae_calc(y_hat, y)
rho = pearsonr(y, y_hat)
mre = torch.mean(torch.abs(y - y_hat) / torch.abs(y))
print("mae: \t{}\nrho: \t{}\nmre: \t{}\n".format(mae, rho, mre))

## Tensorflow
logits = tf.placeholder(tf.float32, [1,8])
labels = tf.to_float(tf.Variable(y_true))

mae, mae_op = tf.metrics.mean_absolute_error(labels, logits)
rho, rho_op = tf.contrib.metrics.streaming_pearson_correlation(labels, logits)
mre, mre_op = tf.metrics.mean_relative_error(labels, logits, labels)

sess = tf.Session()
sess.run(tf.local_variables_initializer())
sess.run(tf.global_variables_initializer())
sess.run(mae, {logits:y_pred})
sess.run(mae_op, {logits:y_pred})
sess.run(rho, {logits:y_pred})
sess.run(rho_op, {logits:y_pred})
sess.run(mre, {logits:y_pred})
sess.run(mre_op, {logits:y_pred})

print("mae: \t{}\nrho: \t{}\nmre: \t{}\n".format(sess.run(mae,{logits:y_pred}), sess.run(rho,{logits:y_pred}), sess.run(mre,{logits:y_pred})))
```

最终计算结果为
```shell
mae:    1.375
rho:    0.38060760498046875
mre:    0.293154776096344

mae:    1.375
rho:    0.38060760498046875
mre:    0.293154776096344
```

测试结果完全相同。